# WMT22 EX and XY Human Evaluation

This subdirectory contains data and scripts collected from human evaluation
campaigns run in [Appraise](https://github.com/AppraiseDev/Appraise).

Files and directories:
* `make_rankings.py` : script computing/checking the rankings
* `batches` : JSON files with Appraise annotation tasks including QC items
* `results` : CSV files with Appraise scores and CSV header files
* `calibration-HITs` : calibration tasks, results and header files
* `scripts` : helper scripts used when creating Appraise campaigns

